{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for the question and answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from mc_challenge.dataset    import Questions, Section, load_mc, convert_to_idx\n",
    "from mc_challenge.validation import validate\n",
    "from mc_challenge.vocab      import Vocab\n",
    "\n",
    "\n",
    "training, validation, test = load_mc(\"data/\", 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the vocabulary from each of the sections of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "section_vocab = Vocab()\n",
    "for section in (training + validation + test):\n",
    "    section_vocab.add_words_from_text(section.text, tokenization = True)\n",
    "    for q in section.questions:\n",
    "        section_vocab.add_words_from_text(q.question, tokenization = True)\n",
    "        for a in q.answers:\n",
    "            section_vocab.add_words_from_text(a, tokenization = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the words that only appear in the questions and answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Who', 328),\n",
       " ('Which', 78),\n",
       " ('Blue', 35),\n",
       " ('Green', 29),\n",
       " ('Play', 27),\n",
       " ('White', 26),\n",
       " ('4', 24),\n",
       " ('An', 24),\n",
       " ('Yellow', 23),\n",
       " ('Black', 23)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_vocab_no_q = Vocab()\n",
    "for section in (training + validation + test):\n",
    "    section_vocab_no_q.add_words_from_text(section.text, tokenization=True)\n",
    "delta_voc = section_vocab - section_vocab_no_q\n",
    "delta_voc.word_occ.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a vocabulary we convert the sections to numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_idx   = convert_to_idx(training, section_vocab)\n",
    "validation_idx = convert_to_idx(validation, section_vocab)\n",
    "test_idx       = convert_to_idx(test, section_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First approach, look at word embeddings in quadratic form model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mc_challenge.simple_qform_model import QFormModel\n",
    "from mc_challenge.dragon_model import DragonModel\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_size = 30\n",
    "num_answers = 4\n",
    "vocab_size  = len(section_vocab)\n",
    "\n",
    "#model = QFormModel(hidden_size, vocab_size, num_answers)\n",
    "model = DragonModel(hidden_size=100,\n",
    "                    internal_features=100,\n",
    "                    intermediate_size=100,\n",
    "                    vocab_size=vocab_size,\n",
    "                    num_answers=num_answers,\n",
    "                    tensor=False,\n",
    "                    method=\"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.lr.set_value(0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_sentence  = section_vocab(training[0].text,                    True)\n",
    "np_question  = section_vocab(training[0].questions[0].question,   True)\n",
    "np_answer1   = section_vocab(training[0].questions[0].answers[0], True)\n",
    "np_answer2   = section_vocab(training[0].questions[0].answers[1], True)\n",
    "np_answer3   = section_vocab(training[0].questions[0].answers[2], True)\n",
    "np_answer4   = section_vocab(training[0].questions[0].answers[3], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(2.8262931067785217)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.error_fun(\n",
    "    np_sentence,\n",
    "    np_question,\n",
    "    np_answer1,\n",
    "    1.0,\n",
    "    np_answer2,\n",
    "    0.0,\n",
    "    np_answer3,\n",
    "    0.0,\n",
    "    np_answer4,\n",
    "    0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_score(model):\n",
    "    return validate(test, model, section_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3107142857142857"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: error validation accuracy 32.78%, training error 2.20327\n",
      "epoch 0: error validation accuracy 30.56%, training error 2.17825\n",
      "epoch 0: error validation accuracy 32.22%, training error 2.19355\n",
      "epoch 0: error validation accuracy 32.22%, training error 2.17944\n",
      "epoch 0: error validation accuracy 34.44%, training error 2.16054\n",
      "epoch 0: error validation accuracy 32.78%, training error 2.17995\n",
      "epoch 0: error validation accuracy 32.22%, training error 2.18094\n",
      "epoch 0: error validation accuracy 31.11%, training error 2.17573\n",
      "epoch 1: error validation accuracy 31.11%, training error 2.18240\n",
      "epoch 1: error validation accuracy 31.11%, training error 2.17901\n",
      "epoch 1: error validation accuracy 31.67%, training error 2.18629\n",
      "epoch 1: error validation accuracy 31.67%, training error 2.19333\n",
      "epoch 1: error validation accuracy 32.78%, training error 2.17707\n",
      "epoch 1: error validation accuracy 31.67%, training error 2.17446\n",
      "epoch 1: error validation accuracy 32.78%, training error 2.16149\n",
      "epoch 1: error validation accuracy 31.67%, training error 2.15560\n",
      "epoch 2: error validation accuracy 32.78%, training error 2.17665\n",
      "epoch 2: error validation accuracy 32.78%, training error 2.17398\n",
      "epoch 2: error validation accuracy 32.78%, training error 2.16548\n",
      "epoch 2: error validation accuracy 31.67%, training error 2.14987\n",
      "epoch 2: error validation accuracy 31.67%, training error 2.18079\n",
      "epoch 2: error validation accuracy 31.11%, training error 2.17122\n",
      "epoch 2: error validation accuracy 31.11%, training error 2.19019\n",
      "epoch 2: error validation accuracy 32.78%, training error 2.17331\n",
      "epoch 3: error validation accuracy 33.33%, training error 2.17942\n",
      "epoch 3: error validation accuracy 33.33%, training error 2.18646\n",
      "epoch 3: error validation accuracy 33.33%, training error 2.15796\n",
      "epoch 3: error validation accuracy 31.67%, training error 2.14600\n",
      "epoch 3: error validation accuracy 32.22%, training error 2.17348\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-745f70860740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_seen\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mval_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection_vocab\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch %d: error validation accuracy %.2f%%, training error %.5f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jonathanraiman/Desktop/Coding/mc_challenge/mc_challenge/validation.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(sections, model, vocabulary)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msection\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msections\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mnum_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalidate_section\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnum_correct\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jonathanraiman/Desktop/Coding/mc_challenge/mc_challenge/validation.py\u001b[0m in \u001b[0;36mvalidate_section\u001b[0;34m(section, model, vocabulary)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             tokenization = True) for ans in question.answers]\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jonathanraiman/Desktop/Coding/mc_challenge/mc_challenge/dragon_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, text, question_idx, answers_idx)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         return np.array(\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_triplet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manswers_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         ).argmax()\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jonathanraiman/Desktop/Coding/mc_challenge/mc_challenge/dragon_model.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         return np.array(\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_triplet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manswers_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         ).argmax()\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for section in range(section\n",
    "num_seen = 0\n",
    "minibatch_size = 200\n",
    "max_epochs = 200\n",
    "error = 0.0\n",
    "training_order = np.arange(0, len(training_idx))\n",
    "for epoch in range(max_epochs):\n",
    "    np.random.shuffle(training_order)\n",
    "    for section_i in training_order:\n",
    "        section = training_idx[section_i]\n",
    "        for q in section.questions:\n",
    "            q_idx, ans_idx, correct_ans = q\n",
    "            error += model.update_gradient(\n",
    "                section.text,\n",
    "                q_idx,\n",
    "                ans_idx[0],\n",
    "                1.0 if correct_ans == 0 else 0.0,\n",
    "                ans_idx[1],\n",
    "                1.0 if correct_ans == 1 else 0.0,\n",
    "                ans_idx[2],\n",
    "                1.0 if correct_ans == 2 else 0.0,\n",
    "                ans_idx[3],\n",
    "                1.0 if correct_ans == 3 else 0.0)\n",
    "            num_seen += 1\n",
    "            if (num_seen % minibatch_size) == 0:\n",
    "                model.apply_gradient()\n",
    "                val_error = validate(validation, model, section_vocab) * 100.0\n",
    "                \n",
    "                print(\"epoch %d: error validation accuracy %.2f%%, training error %.5f\" % (epoch, val_error, error / minibatch_size))\n",
    "                error = 0.0\n",
    "                \n",
    "            #if (num_seen % (10 * minibatch_size)) == 0:\n",
    "            #    model.reset_caches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
