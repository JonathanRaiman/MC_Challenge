{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "name": "",
  "signature": "sha256:c17435273c89f8944cc89766602bb7ed6e700a210415a288c6b4992142142f6b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Model for the question and answers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "from mc_challenge.dataset import Questions, Section, load_mc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "training, validation, test = load_mc(\"data/\", 0.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(len(training))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "405\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from mc_challenge.vocab import Vocab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Collect the vocabulary from each of the sections of the dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "section_vocab = Vocab()\n",
      "for section in training + validation + test:\n",
      "    section_vocab.add_words_from_text(section.text, tokenization = True)\n",
      "    for q in section.questions:\n",
      "        section_vocab.add_words_from_text(q.question, tokenization = True)\n",
      "        for a in q.answers:\n",
      "            section_vocab.add_words_from_text(a, tokenization = True)"
     ],
     "language": "python",
     "metadata": {
      "scrolled": false
     },
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Find the words that only appear in the questions and answers:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "section_vocab_no_q = Vocab()\n",
      "for section in tsv_sets:\n",
      "    section_vocab_no_q.add_words_from_text(section.text, tokenization=True)\n",
      "delta_voc = section_vocab - section_vocab_no_q\n",
      "delta_voc.word_occ.most_common(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "[('Who', 328),\n",
        " ('Which', 78),\n",
        " ('Blue', 35),\n",
        " ('Green', 29),\n",
        " ('Play', 27),\n",
        " ('White', 26),\n",
        " ('An', 24),\n",
        " ('4', 24),\n",
        " ('Yellow', 23),\n",
        " ('Black', 23)]"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First approach, look at word embeddings in quadratic form model:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import theano, theano.tensor as T\n",
      "import numpy as np\n",
      "from theano_lstm import Layer, Embedding, create_optimization_updates\n",
      "\n",
      "def create_shared(name=\"\", *dims):\n",
      "    return theano.shared(np.random.uniform(\n",
      "            low=-1.0 / np.sqrt(dims[0]),\n",
      "            high=1.0 / np.sqrt(dims[0]), size=dims).astype(theano.config.floatX), name=name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 209
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hidden_size = 30\n",
      "num_answers = 4\n",
      "vocab_size =  len(section_vocab)\n",
      "\n",
      "embedding = Embedding(vocab_size, hidden_size)\n",
      "q_form = create_shared(\"tensor\", 1, hidden_size, hidden_size)\n",
      "\n",
      "def embed(sequence):\n",
      "    return embedding.activate(sequence).mean(axis=0)\n",
      "\n",
      "def question_representation(sentence, question):\n",
      "    \"\"\"\n",
      "    Take the mean embedding of the words in the text and\n",
      "    the mean of the question, and the mean of\n",
      "    use that to predict an answer\n",
      "    \"\"\"\n",
      "    return embed(sentence) * embed(question)\n",
      "\n",
      "def quadratic_form(tensor, x, y):\n",
      "    return (T.dot(tensor, x.T) * y.T).sum(axis=1).T\n",
      "\n",
      "def answer_score(question_rep, answer_rep):\n",
      "    \"\"\"\n",
      "    Score an answer based on its interaction with the embedding of\n",
      "    a question and text.\n",
      "    \"\"\"\n",
      "    return T.nnet.sigmoid(quadratic_form(\n",
      "        q_form,\n",
      "        answer_rep,\n",
      "        question_rep))\n",
      "\n",
      "def get_score(s, q, a):\n",
      "    q_rep = T.tanh(question_representation(s, q))\n",
      "    a_rep = embed(a)\n",
      "    return answer_score(q_rep, a_rep)\n",
      "\n",
      "\n",
      "sentence = T.ivector()\n",
      "question = T.ivector()\n",
      "answer   = T.ivector()\n",
      "params = embedding.params + [q_form]\n",
      "\n",
      "score_triplet = theano.function([sentence, question, answer], get_score(sentence, question, answer), allow_input_downcast=True)\n",
      "\n",
      "def get_error(s, q, *answer_target):\n",
      "    q_rep = T.tanh(question_representation(s, q))\n",
      "    error = 0.0\n",
      "    i = 0\n",
      "    while i < len(answer_target):\n",
      "        a_rep = embed(answer_target[i])\n",
      "        score = answer_score(q_rep, a_rep)\n",
      "        error += T.nnet.binary_crossentropy(score[0], answer_target[i+1])\n",
      "        i+=2\n",
      "    return error\n",
      "\n",
      "answers = [T.ivector() for i in range(4)]\n",
      "targets = [T.fscalar() for i in range(4)]\n",
      "answer_targets = []\n",
      "for a, t in zip(answers, targets):\n",
      "    answer_targets.extend([a, t])\n",
      "\n",
      "error = get_error(\n",
      "            sentence,\n",
      "            question,\n",
      "            *answer_targets)\n",
      "\n",
      "error_fun = theano.function([\n",
      "        sentence,\n",
      "        question] + answer_targets,\n",
      "        error, allow_input_downcast=True)\n",
      "\n",
      "updates, gsums, xsums, lr, max_norm = create_optimization_updates(error, params, method=\"adadelta\")\n",
      "\n",
      "update_fun = theano.function([\n",
      "        sentence,\n",
      "        question] + answer_targets,\n",
      "        error,\n",
      "        updates=updates, allow_input_downcast=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 218
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some test data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "np_sentence  = section_vocab(tsv_sets[0].text,                    True)\n",
      "np_question  = section_vocab(tsv_sets[0].questions[0].question,   True)\n",
      "np_answer1   = section_vocab(tsv_sets[0].questions[0].answers[0], True)\n",
      "np_answer2   = section_vocab(tsv_sets[0].questions[0].answers[1], True)\n",
      "np_answer3   = section_vocab(tsv_sets[0].questions[0].answers[2], True)\n",
      "np_answer4   = section_vocab(tsv_sets[0].questions[0].answers[3], True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "error_fun(\n",
      "    np_sentence,\n",
      "    np_question,\n",
      "    np_answer1,\n",
      "    1.0,\n",
      "    np_answer2,\n",
      "    0.0,\n",
      "    np_answer3,\n",
      "    0.0,\n",
      "    np_answer4,\n",
      "    0.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 208,
       "text": [
        "array(2.772588722217114)"
       ]
      }
     ],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}